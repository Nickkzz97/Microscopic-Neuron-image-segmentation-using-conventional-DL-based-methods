{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet_train_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDhmCeSzFItM6RlKfYCuUh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qh_C2T0XibC","executionInfo":{"status":"ok","timestamp":1606580776605,"user_tz":-330,"elapsed":25757,"user":{"displayName":"Nicky Nirlipta Sahoo ee19s042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrUkW_iz_OT_r11_3fG-AqoZ4BjhUcaKpDT1Up=s64","userId":"09388294964763469602"}},"outputId":"bd41c50d-80b0-4647-ed0a-203448b81908"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhRcq73fXqx6","executionInfo":{"status":"ok","timestamp":1606580994354,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Nicky Nirlipta Sahoo ee19s042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrUkW_iz_OT_r11_3fG-AqoZ4BjhUcaKpDT1Up=s64","userId":"09388294964763469602"}},"outputId":"6dac5dcb-99d3-4936-cbab-7e1c255dcbb1"},"source":["cd /gdrive/My Drive/Biomedical Image Processing ED6001/Final Submission/Code/unet_em_image"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/Biomedical Image Processing ED6001/Final Submission/Code/unet_em_image\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uWO0jukxZHa5"},"source":["from __future__ import print_function\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np \n","import os\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n"," \n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pNbvMht1ZNJr"},"source":["#data augmentation#\n","In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied.\n","\n","keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time.\n","\n","It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on... see keras documentation for detail.\n","\n","For image segmentation tasks, the image and mask must be transformed together!!"]},{"cell_type":"code","metadata":{"id":"iHq0G1IHZMB4"},"source":["#data generation\n","Sky = [128,128,128]\n","Building = [128,0,0]\n","Pole = [192,192,128]\n","Road = [128,64,128]\n","Pavement = [60,40,222]\n","Tree = [128,128,0]\n","SignSymbol = [192,128,128]\n","Fence = [64,64,128]\n","Car = [64,0,128]\n","Pedestrian = [64,64,0]\n","Bicyclist = [0,128,192]\n","Unlabelled = [0,0,0]\n","\n","COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n","                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n","\n","\n","def adjustData(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img = img / 255\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        for i in range(num_class):\n","            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n","            #index = np.where(mask == i)\n","            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n","            #new_mask[index_mask] = 1\n","            new_mask[mask == i,i] = 1\n","        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n","        mask = new_mask\n","    elif(np.max(img) > 1):\n","        img = img / 255\n","        mask = mask /255\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","\n","\n","def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n","                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n","    '''\n","    can generate image and mask at the same time\n","    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n","    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n","    '''\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        train_path,\n","        classes = [image_folder],\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        train_path,\n","        classes = [mask_folder],\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoriQ79DZYs2"},"source":["#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n","#data_gen_args = dict()\n","\n","data_gen_args = dict(rotation_range=0.2,\n","                    width_shift_range=0.05,\n","                    height_shift_range=0.05,\n","                    shear_range=0.05,\n","                    zoom_range=0.05,\n","                    horizontal_flip=True,\n","                    fill_mode='nearest')\n","myGenerator = trainGenerator(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)#\"data/membrane/train/train_augmented\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DGq2Y8eKZdUn"},"source":["visualize your data augmentation result"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkwZKpf8ZcWd","executionInfo":{"status":"ok","timestamp":1606581053800,"user_tz":-330,"elapsed":18467,"user":{"displayName":"Nicky Nirlipta Sahoo ee19s042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrUkW_iz_OT_r11_3fG-AqoZ4BjhUcaKpDT1Up=s64","userId":"09388294964763469602"}},"outputId":"fdee070e-645a-436e-87cb-be24019110ef"},"source":["#you will see 60 transformed images and their masks in data/membrane/train/aug\n","num_batch = 3\n","for i,batch in enumerate(myGenerator):\n","    if(i >= num_batch):\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 30 images belonging to 1 classes.\n","Found 30 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N_kAUPOBZuGU"},"source":["# Model Generation"]},{"cell_type":"code","metadata":{"id":"0j_mLd1pZtac"},"source":["def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)   ##### 64 features\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)                                                           ######### Transition Down\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n"," \n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n"," \n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))  ######Transition Up\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n"," \n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n"," \n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n"," \n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n"," \n","    model = Model(inputs = inputs, outputs = conv10)\n"," \n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n"," \n","    if(pretrained_weights):\n","        model.load_weights(pretrained_weights)\n"," \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RqG074MVZ1g8"},"source":["Train with data generator"]},{"cell_type":"code","metadata":{"id":"y96WYdWqZkVi"},"source":["data_gen_args = dict(rotation_range=0.2,\n","                    width_shift_range=0.05,\n","                    height_shift_range=0.05,\n","                    shear_range=0.05,\n","                    zoom_range=0.05,\n","                    horizontal_flip=True,\n","                    fill_mode='nearest')\n","myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)\n","model = unet()\n","model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pBfd2rCsjra","executionInfo":{"status":"ok","timestamp":1606581571343,"user_tz":-330,"elapsed":1032,"user":{"displayName":"Nicky Nirlipta Sahoo ee19s042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrUkW_iz_OT_r11_3fG-AqoZ4BjhUcaKpDT1Up=s64","userId":"09388294964763469602"}},"outputId":"afe3e20a-62d4-418d-e5d3-83d8ca56c113"},"source":["# from matplotlib import pyplot as plt \n","# a=plt.imread('data/membrane/train/image/0.png')\n","# a.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(512, 512)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbNz5IP-Z59h","outputId":"c1e9b5cb-34f4-4879-a99e-331d1d9b11b4"},"source":["model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","2000/2000 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9182 \n","Epoch 00001: loss improved from inf to 0.18669, saving model to unet_membrane.hdf5\n","2000/2000 [==============================] - 27410s 14s/step - loss: 0.1867 - accuracy: 0.9182\n","Epoch 2/5\n"," 947/2000 [=============>................] - ETA: 4:00:30 - loss: 0.1327 - accuracy: 0.9417"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yto22ec05Lv","executionInfo":{"status":"ok","timestamp":1606583522159,"user_tz":-330,"elapsed":1456,"user":{"displayName":"Nicky Nirlipta Sahoo ee19s042","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrUkW_iz_OT_r11_3fG-AqoZ4BjhUcaKpDT1Up=s64","userId":"09388294964763469602"}},"outputId":"135dc910-34ed-4eb3-b1d8-c9482958f0b2"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n","                                                                 conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n","                                                                 conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n","                                                                 conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n","                                                                 conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 256, 256, 1)  3           conv2d_22[0][0]                  \n","==================================================================================================\n","Total params: 31,031,685\n","Trainable params: 31,031,685\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LDGwPTJNaSc8"},"source":["test your model and save predicted results"]},{"cell_type":"code","metadata":{"id":"7DIPORPOfk4P"},"source":["def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n","    for i in range(num_image):\n","        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n","        img = img / 255\n","        img = trans.resize(img,target_size)\n","        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n","        img = np.reshape(img,(1,)+img.shape)\n","        yield img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SgX2A18CaJc1"},"source":["testGene = testGenerator(\"data/membrane/test_1\")\n","model = unet()\n","model.load_weights(\"unet_membrane.hdf5\")\n","results = model.predict_generator(testGene,30,verbose=1)\n","saveResult(\"data/membrane/test_result\",results)"],"execution_count":null,"outputs":[]}]}